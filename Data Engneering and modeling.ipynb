{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff12506-230e-4163-9443-1c97af71fa28",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcd94b-86e6-4df9-ad2d-0bd55c137da8",
   "metadata": {},
   "source": [
    "### •\tGenerate new features to support later modeling (e.g., price per square meter, total rooms, encoded categorical values).\n",
    "### •\tApply appropriate feature scaling (e.g., MinMaxScaler, StandardScaler).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdccb33b-4eea-4139-8d1c-01eb41e0ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Shape: (558, 6)\n",
      "Columns: ['bedrooms', 'bathrooms', 'property_type', 'title', 'price', 'source']\n",
      "\n",
      "Missing values:\n",
      "bedrooms         0\n",
      "bathrooms        0\n",
      "property_type    0\n",
      "title            0\n",
      "price            0\n",
      "source           0\n",
      "dtype: int64\n",
      "Created total_rooms feature\n",
      "Created price_per_bedroom feature\n",
      "\n",
      "Categorical columns: ['property_type', 'title', 'source']\n",
      "Encoded property_type -> property_type_encoded\n",
      "Encoded title -> title_encoded\n",
      "Encoded source -> source_encoded\n",
      "\n",
      "Cleaned dataset shape: (558, 8)\n",
      "Columns to scale: 7\n",
      "Scaling completed\n",
      "Saved features_engineered.csv\n",
      "\n",
      "SUMMARY:\n",
      "Original columns: 11\n",
      "Final columns: 8\n",
      "Rows: 558\n",
      "\n",
      "Top 5 features most correlated with price:\n",
      "price                    1.000000\n",
      "price_per_bedroom        0.586067\n",
      "bathrooms                0.362752\n",
      "total_rooms              0.358535\n",
      "bedrooms                 0.346896\n",
      "property_type_encoded    0.250079\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('merged_final.csv')\n",
    "print(\"Data loaded successfully\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# STEP 1: CREATE NEW FEATURES\n",
    "# These are simple calculations that might help the model understand patterns better\n",
    "\n",
    "# Price per square meter - this is very important for real estate\n",
    "# It tells us how expensive each square meter is\n",
    "if 'price' in df.columns and 'area' in df.columns:\n",
    "    df['price_per_sqm'] = df['price'] / df['area']\n",
    "    print(\"Created price_per_sqm feature\")\n",
    "\n",
    "# Total number of rooms - bedrooms + bathrooms\n",
    "# More rooms usually means higher price\n",
    "if 'bedrooms' in df.columns and 'bathrooms' in df.columns:\n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    print(\"Created total_rooms feature\")\n",
    "\n",
    "# Price per bedroom - how much you pay per bedroom\n",
    "# Useful to compare properties with different bedroom counts\n",
    "if 'price' in df.columns and 'bedrooms' in df.columns:\n",
    "    df['price_per_bedroom'] = df['price'] / df['bedrooms']\n",
    "    print(\"Created price_per_bedroom feature\")\n",
    "\n",
    "# Property age - how old is the property\n",
    "# Newer properties might be more expensive\n",
    "if 'year_built' in df.columns:\n",
    "    current_year = 2024\n",
    "    df['property_age'] = current_year - df['year_built']\n",
    "    print(\"Created property_age feature\")\n",
    "\n",
    "# Area in different scales - sometimes models work better with transformed data\n",
    "if 'area' in df.columns:\n",
    "    df['area_squared'] = df['area'] ** 2  # Square of area\n",
    "    df['area_log'] = np.log(df['area'] + 1)  # Log of area (adding 1 to avoid log(0))\n",
    "    print(\"Created area_squared and area_log features\")\n",
    "\n",
    "# STEP 2: HANDLE CATEGORICAL VARIABLES\n",
    "# Categorical variables are non-numeric like 'city', 'property_type'\n",
    "# Models need numbers, so we convert categories to numbers\n",
    "\n",
    "# Find all text/categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nCategorical columns: {categorical_cols}\")\n",
    "\n",
    "# For each categorical column, convert to numbers\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        # LabelEncoder converts categories to numbers (0, 1, 2, etc.)\n",
    "        # For example: 'apartment' becomes 0, 'house' becomes 1\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        # Fill missing values with 'Unknown' first\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "        \n",
    "        # Create new column with encoded values\n",
    "        df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "        print(f\"Encoded {col} -> {col}_encoded\")\n",
    "\n",
    "# STEP 3: REMOVE PROBLEMATIC VALUES\n",
    "# Replace infinite values with NaN (happens when dividing by zero)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill any remaining NaN values with the median (middle value)\n",
    "# Median is better than mean because it's not affected by extreme values\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_value = df[col].median()\n",
    "        df[col] = df[col].fillna(median_value)\n",
    "        print(f\"Filled missing values in {col} with median: {median_value}\")\n",
    "\n",
    "# STEP 4: PREPARE DATA FOR SCALING\n",
    "# Remove original categorical columns since we have encoded versions\n",
    "cols_to_drop = []\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "# Also remove any ID columns or index columns\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    cols_to_drop.append('Unnamed: 0')\n",
    "\n",
    "# Create clean dataset without categorical columns\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# STEP 5: FEATURE SCALING\n",
    "# Scaling makes all features have similar ranges\n",
    "# This helps many machine learning algorithms work better\n",
    "\n",
    "# Get list of columns to scale (all numeric columns except target)\n",
    "# Assuming 'price' is your target variable\n",
    "cols_to_scale = df_clean.columns.tolist()\n",
    "if 'price' in cols_to_scale:\n",
    "    cols_to_scale.remove('price')  # Don't scale the target variable\n",
    "\n",
    "print(f\"Columns to scale: {len(cols_to_scale)}\")\n",
    "\n",
    "# Method 1: StandardScaler\n",
    "# Makes features have mean=0 and standard deviation=1\n",
    "# Good for most algorithms like linear regression, SVM\n",
    "scaler_std = StandardScaler()\n",
    "df_standardized = df_clean.copy()\n",
    "df_standardized[cols_to_scale] = scaler_std.fit_transform(df_clean[cols_to_scale])\n",
    "\n",
    "# Method 2: MinMaxScaler  \n",
    "# Makes features range from 0 to 1\n",
    "# Good for neural networks and algorithms sensitive to outliers\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = df_clean.copy()\n",
    "df_minmax[cols_to_scale] = scaler_minmax.fit_transform(df_clean[cols_to_scale])\n",
    "\n",
    "print(\"Scaling completed\")\n",
    "\n",
    "# STEP 6: SAVE THE RESULTS\n",
    "# Save one clean file ready for modeling\n",
    "\n",
    "# Use standardized features (good for most models)\n",
    "df_standardized.to_csv('features_engineered.csv', index=False)\n",
    "print(\"Saved features_engineered.csv\")\n",
    "\n",
    "# STEP 7: SUMMARY\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"Final columns: {len(df_clean.columns)}\")\n",
    "print(f\"Rows: {len(df_clean)}\")\n",
    "\n",
    "# Show correlation with price if it exists\n",
    "if 'price' in df_clean.columns:\n",
    "    print(f\"\\nTop 5 features most correlated with price:\")\n",
    "    correlations = df_clean.corr()['price'].abs().sort_values(ascending=False)\n",
    "    print(correlations.head(6))  # Top 6 includes price itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97481efe-906e-4058-b8f2-689705a6800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Shape: (558, 8)\n",
      "Columns: ['bedrooms', 'bathrooms', 'price', 'total_rooms', 'price_per_bedroom', 'property_type_encoded', 'title_encoded', 'source_encoded']\n",
      "Data split into training and testing sets\n",
      "\n",
      "Linear Regression Results:\n",
      "RMSE: 89744.82\n",
      "R² Score: 0.65\n",
      "\n",
      "Random Forest Results:\n",
      "RMSE: 52045.22\n",
      "R² Score: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('features_engineered.csv')\n",
    "print(\"Data loaded\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "#target\n",
    "target = 'price'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Optional: drop any non-numeric columns (in case encoding failed earlier)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Step 3: Scale features (optional but helpful for linear models)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split into training and testing sets\")\n",
    "\n",
    "# Train models\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(\"Linear Regression\", y_test, lr_preds)\n",
    "evaluate_model(\"Random Forest\", y_test, rf_preds)\n",
    "\n",
    "# Save the better model (e.g., Random Forest)\n",
    "joblib.dump(rf, 'best_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d7c9c-4608-4cfd-bed0-66009c86264d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
